{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Практическое задание 2 (часть 1)\n",
    "\n",
    "# Определение частей речи с помощью скрытой марковской модели\n",
    "\n",
    "## курс \"Математические методы анализа текстов\"\n",
    "\n",
    "\n",
    "### ФИО: <впишите>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Введение\n",
    "\n",
    "### Постановка задачи\n",
    "\n",
    "В данной лабораторной работе вам предстоит обучить скрытую марковскую модель на размеченных данных и реализовать алгоритм Витерби для задачи POS-теггинга (определение частей речи слов в тексте), а также ознакомиться с использованием  ряда POS-теггеров из библиотеки NLTK.\n",
    "\n",
    "### Комментарии и советы\n",
    "\n",
    "1. Для выполнения потребуются модули Python numpy, nltk.\n",
    "\n",
    "2. Все необходимые для выполнения задания данные либо приложены, либо могут быть скачаны с помощью nltk.download().\n",
    "\n",
    "3. Посмотреть параметры конструктора и других методов классов можно набрав и выполнив в ячейке с кодом '?full_method_name'.\n",
    "\n",
    "### Задача определения частей речи (POS)\n",
    "\n",
    "Мы будем решать задачу определения частей речи (POS-теггинга) с помощью скрытой марковской модели (HMM). Формула совместной плотности наблюдаемых и скрытых переменных задается как\n",
    "\n",
    "$$ p(x, t) = p(t) p(x|t) = p(t_1)  \\prod_{i=2}^{N_x} p(t_i|t_{i-1}) \\prod_{i=1}^{N_x} p(x_i|t_i)$$\n",
    "\n",
    "#### Переменные модели\n",
    "\n",
    "- наблюдаемые переменные $X$ - словарь корпуса;\n",
    "\n",
    "- скрытые переменные $T$ - множество POS-тегов.\n",
    "\n",
    "- x - одно предложение, $N_x$ - длина предложения\n",
    "\n",
    "- t - теги одного предложения, $N_t$ - длина вектора меток\n",
    "\n",
    "#### Параметры модели\n",
    "\n",
    "- матрица вероятностей переходов $A \\in \\mathbb{R}^{|T| \\times |T|}$, $A_{ij} = p(t_s=i|t_{s-1}=j) \\; \\forall s$\n",
    "\n",
    "- матрица выходных вероятностей $B \\in \\mathbb{R}^{|X| \\times |T|}$, $B_{ij} = p(x_s =i|t_s =j) \\; \\forall s$\n",
    "\n",
    "- вектор начальных вероятностей $C \\in \\mathbb{R}^{|T|}$, $C_i = p(t_1=i)$\n",
    "\n",
    "\n",
    "#### Обучение модели\n",
    "\n",
    "* Для обучения параметров $A$ и $B$ используется метод максимума правдоподобия. Оценки вычисляются на основе частот совстречаемости тегов и тегов со словами:\n",
    "\n",
    "$$a_{ij} = \\frac{\\sum_{t}\\sum_{s=2}^{N_t} \\mathbb{I}[t_{s} = i, t_{s - 1} = j]}{\\sum_{t}\\sum_{s=2}^{N_t} \\mathbb{I}[t_{s-1} = j]}$$\n",
    "\n",
    "$$b_{ij} = \\frac{\\sum_{t, x}\\sum_{s=1}^{N_t} \\mathbb{I}[x_{s} = i, t_{s} = j]}{\\sum_{t, x}\\sum_{s=1}^{N_t} \\mathbb{I}[t_{s} = j]}$$\n",
    "\n",
    "* Параметры $C$ можно аналогично вычислять по частотам или считать распределение $p(t_1)$ равномерным"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Применение модели\n",
    "\n",
    "Применение модели на новых данных реализуется с помощью алгоритма Витерби.Это алгоритм динамиеского программирования, с помощью которого мы будем находить наиболее вероятную последовательность скрытых состояний модели для фиксированной последовательности слов:\n",
    "\n",
    "$$ \\hat{t} = \\arg \\max_{t} p(t|x) = \\arg \\max_{t} p(x, t) $$\n",
    "\n",
    "Определим функцию, определяющую максимальную вероятность последовательности, заканчивающейся на $i$-ой позиции в состоянии $k$:\n",
    "\n",
    "$$\\delta(k, i) = \\max_{t_1, \\dots t_{i-1}} p(x_1, \\dots x_i, t_1, \\dots t_i=k)$$\n",
    "\n",
    "Тогда $\\max_{k} \\delta(k, N_x)$ - максимальная вероятность всей последовательности. А состояния, на которых эта вероятность достигается - ответ задачи.\n",
    "\n",
    "Алгоритм Витерби заключается в последовательном пересчете функции $\\delta(k, i)$ по формуле:\n",
    "\n",
    "$$\\delta(k, i) = \\max_{m} \\delta(m, i-1) p(t_i = k|t_{i-1} = m) p(x_i|t_i=k) $$\n",
    "\n",
    "Аналогично пересчитывается функция, определяющая, на каком состоянии этот максимум достигается:\n",
    "\n",
    "$$s(k, i) = \\arg \\max_{m} \\delta(m, i-1) p(t_i = k|t_{i-1} = m) p(x_i|t_i=k) $$\n",
    "\n",
    "\n",
    "На практике это означает заполнение двумерных массивов размерности: (длина последовательности) $\\times$ (количество возможных состояний). Когда массивы заполнены, $\\arg \\max_{k} \\delta(k, N_x)$ говорит о последнем состоянии. Начиная с него можно восстановить все состояния по массиву $s$. \n",
    "\n",
    "Осталось уточнить, как стартовать последовательный пересчет (чем заполнить первый столбец массива вероятностей):\n",
    "\n",
    "$$\\delta(k, 1) = p(k) p(x_1|t_1=k)$$\n",
    "\n",
    "Подробнее о HMM можно прочитать по [ссылке](https://web.stanford.edu/~jurafsky/slp3/A.pdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Часть 1. Загрузка корпуса (1 балл)\n",
    "\n",
    "Загрузите brown корпус с универсальной системой тегирования. Для этого вам понадобятся ресурсы brown и universal_tagset из nltk.download().  \n",
    "\n",
    "Так как каждый конкретный датасет может использовать свою систему тегов, в NLTK предусмотрено универсальное множество тегов и возможность приведения к нему других систем. Это множество включает в себя следующие теги:\n",
    "\n",
    "\n",
    "- ADJ - adjective (new, good, high, ...)\n",
    "- ADP - adposition\t(on, of, at, ...)\n",
    "- ADV - adverb\t(really, already, still, ...)\n",
    "- CONJ\t- conjunction\t(and, or, but, ...)\n",
    "- DET - determiner, article\t(the, a, some, ...)\n",
    "- NOUN\t- noun\t(year, home, costs, ...)\n",
    "- NUM - numeral\t(twenty-four, fourth, 1991, ...)\n",
    "- PRT -\tparticle (at, on, out, ...)\n",
    "- PRON - pronoun (he, their, her, ...)\n",
    "- VERB - verb (is, say, told, ...)\n",
    "- .\t- punctuation marks\t(. , ;)\n",
    "- X\t- other\t(ersatz, esprit, dunno, ...)\n",
    "\n",
    "Обратите внимание, что тегсеты в корпусах текстов и в различных теггерах могут быть разными. Проверять это можно, глядя на сами теги, а симптом - подозрительно низкое качество теггирования. В таких случаях рекомендуется всё приводить сперва к универсальному тегсету, а потом уже мерять качество. Полезной может оказаться эта ссылка http://www.nltk.org/_modules/nltk/tag/mapping.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import brown\n",
    "\n",
    "brown_tagged_sents = brown.tagged_sents(tagset=\"universal\")\n",
    "\n",
    "# you code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Проанализируйте данные, с которыми Вы работаете. В частности, ответьте на вопросы:\n",
    "- Каков общий объем датасета, формат?\n",
    "- Приведены ли слова к нижнему регистру? Чем  это нам может в дальнейшем помешать?\n",
    "- Как распределены слова в корпусе?  Как распределены теги в корпусе? Подсчитайте частоты и отобразите любым удобным для Вас способом. Проинтерпретируйте полученные результаты."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your answers here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cделайте случайное разбиение выборки на обучение и контроль в отношении 9:1.Если впоследствии обучение моделей будет занимать слишком много времени, работайте с подвыборкой, например, только текстами определенных категорий."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Часть 2. Скрытая марковская модель (4 балла) \n",
    "\n",
    "### Метод максимального правдоподобия для обучения модели\n",
    "\n",
    "Требуется построить скрытую марковскую модель (class HiddenMarkovModel) и написать метод fit для настройки всех её параметров с помощью оценок максимального правдоподобия по размеченным данным (последовательности пар слово+тег):\n",
    "\n",
    "- Вероятности переходов между скрытыми состояниями $p(t_i | t_{i - 1})$ посчитайте на основе частот биграмм POS-тегов.\n",
    "\n",
    "- Вероятности эмиссий наблюдаемых состояний $p(x_i | t_i)$ посчитайте на основе частот \"POS-тег - слово\".\n",
    "\n",
    "- Обратите внимание на проблему разреженности счетчиков и сделаейте все вероятности сглаженными по Лапласу ([add-k smoothing](https://en.wikipedia.org/wiki/Additive_smoothing)).\n",
    "\n",
    "- Распределение вероятностей начальных состояний $p(t_1)$ задайте равномерным.\n",
    "\n",
    "\n",
    "### Алгоритм Витерби для применения модели\n",
    "\n",
    "Требуется написать метод .predict для определения частей речи на тестовой выборке. Чтобы использовать обученную модель на новых данных, необходимо реализовать алгоритм Витерби. \n",
    "\n",
    "В реализации рекомендуется перейти к логарифмам, т.к. произведение большого числа маленьких вероятностей может приводить к вычислительным ошибкам."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HiddenMarkovModel:    \n",
    "    def __init__(self, k_smoothing=1.0):\n",
    "        \"\"\"\n",
    "        k_smoothing : float, constant in add-k-smoothing\n",
    "        \"\"\"\n",
    "        self.k_smoothing = k_smoothing\n",
    "        \n",
    "    def fit(self, train_tokens_tags_list):\n",
    "        \"\"\"\n",
    "        Fit the model using maximum likelihood method.\n",
    "        \n",
    "        train_tokens_tags_list: list of list of pairs (token, tag) \n",
    "        \"\"\"\n",
    "        pass\n",
    "    \n",
    "    def predict(self, test_tokens_list):\n",
    "        \"\"\"\n",
    "        Return predictions for test_tokens_list using viterbi algorithm.\n",
    "        \n",
    "        test_tokens_list : list of list of tokens\n",
    "        \n",
    "        return: list of list of tags\n",
    "        \"\"\"\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обучите скрытую марковскую модель:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Проверьте работу реализованного алгоритма на следующих модельных примерах, проинтерпретируйте результат.\n",
    "\n",
    "- 'he can stay'\n",
    "- 'a milk can'\n",
    "- 'i saw a dog'\n",
    "- 'an old saw'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Примените модель к отложенной выборке Брауновского корпуса и подсчитайте точность (accuracy) определения тегов (ожидаемая точность $\\approx 0.93$). Сделайте выводы. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Бонусная часть. Сравнение с готовыми POS-теггерами из NLTK (2 балла)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В прошлом пункте Вы реализовали свой POS-тегер на основе скрытой марковской модели. Теперь сравните его работу с готовыми средставми, доступными в библиотеке NLTK: http://www.nltk.org/api/nltk.tag.html\n",
    "\n",
    "Сравните с вашей моделью любые из 4-х теггеров, представленных ниже."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "При проведении экспериментов обращайте внимание на следующие моменты (и отразите их в отчете):\n",
    "- Какой подход лежит в основе теггера\n",
    "- На каких данных он обучен (если Вы скачали готовую модель)\n",
    "- Сколько времени занимает обучение на brown корпусе (если обучаете сами)\n",
    "- Какая точность получается на контролькой выборке\n",
    "\n",
    "Сформируйте рекоммендиции о том, какую технологию Вы бы использовали, если встретитесь с задачей определения частей речи в будущем."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.tag.mapping import map_tag"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. DefaultTagger\n",
    "Простая заглушка, ставящая всем словам один и тот же pos-тег. Очевидно, для максимизации качества, мы хотим выбрать самую частотную метку из всех меток обучающей выборки, т.е. метку 'NOUN'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tag import DefaultTagger\n",
    "default_tagger = DefaultTagger(u'NOUN')\n",
    "\n",
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. RegexpTagger\n",
    "\n",
    "Теггер, который присваивает слову часть речи, основываясь на регулярных выражениях. Например, ставить слову метку 'NOUN', если слово кончается на 'ness'. Ниже приведен простой пример возможных правил. В качестве backoff теггера использован DefaultTagger.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tag import RegexpTagger\n",
    "\n",
    "regexp_tagger = RegexpTagger(regexps=[(r'^-?[0-9]+(.[0-9]+)?$', 'CD'),   # cardinal numbers\n",
    "                                      (r'(The|the|A|a|An|an)$', 'AT'),   # articles\n",
    "                                      (r'.*able$', 'JJ'),                # adjectives\n",
    "                                      (r'.*ness$', 'NN'),                # nouns formed from adjectives\n",
    "                                      (r'.*ly$', 'RB'),                  # adverbs\n",
    "                                      (r'.*s$', 'NNS'),                  # plural nouns\n",
    "                                      (r'.*ing$', 'VBG'),                # gerunds\n",
    "                                      (r'.*ed$', 'VBD'),                 # past tense verbs\n",
    "                                      (r'.*', 'NN')                      # nouns (default)\n",
    "                                     ],\n",
    "                             backoff=default_tagger)\n",
    "\n",
    "# your code here\n",
    "# use map_tag() to tranform 'en-ptb' to 'universal' tags."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. N-грамные теггеры\n",
    "\n",
    "В теггерах, основанных на n-граммах,  принятие решения происходит в зависимости от $n-1$ предыдущих слов и их тегов. Эти теггеры необходимо обучать по размеченной обучающей коллекции. \n",
    "\n",
    "Заметим, что TrigramTagger и BigramTagger работают очень плохо без указания backoff. Поэтому предлагается построить композицию, где \n",
    "в качестве backoff для UnigramTagger использовать DefaultTagger, для BigramTagger использовать UnigramTagger, для TrigramTagger  использовать BigramTagger. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tag import UnigramTagger\n",
    "from nltk.tag import BigramTagger\n",
    "from nltk.tag import TrigramTagger\n",
    "\n",
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Stanford tagger\n",
    "\n",
    "Скачайте предобученную модель от Стэнфорда: https://nlp.stanford.edu/software/tagger.shtml и примените к тестовым данным. \n",
    "Не забудьте преобразовать систему тэгов из 'en-ptb' в 'universal' с помощью функции map_tag."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tag.stanford import StanfordPOSTagger\n",
    "\n",
    "# Add the jar and model via their path:\n",
    "jar = 'you_path_here/stanford-postagger-3.9.1.jar'\n",
    "model = 'your_path_here/models/english-bidirectional-distsim.tagger'\n",
    "stanford_tagger = StanfordPOSTagger(model, jar, encoding='utf8')\n",
    "\n",
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Теггеры из NLTK на основе графических моделей\n",
    "\n",
    "Обучите теггер, основанный на HMM или CRF, на основе класса из nltk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tag import HiddenMarkovModelTagger, CRFTagger\n",
    "\n",
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Сравнение моделей\n",
    "\n",
    "Сравните различные модели по качеству, сделайте выводы."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py36",
   "language": "python",
   "name": "py36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
